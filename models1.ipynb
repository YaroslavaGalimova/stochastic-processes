{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:37:19.716853Z",
     "start_time": "2026-01-19T04:37:12.315760Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import muspy\n",
    "import json\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c7656b032c30f04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T05:19:12.703536Z",
     "start_time": "2026-01-19T05:19:12.409349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "NAME_MUSIC = 'essen'\n",
    "DATA_TOKENS = f\"data/songs_token_{NAME_MUSIC}.json\"\n",
    "MODELS = 'models_exp'\n",
    "songs = []\n",
    "with open(DATA_TOKENS, \"r\", encoding=\"utf-8\") as f:\n",
    "    songs = json.load(f)\n",
    "\n",
    "print(len(songs))\n",
    "print(len(songs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0134d69640fa92f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:37:20.090752Z",
     "start_time": "2026-01-19T04:37:20.080651Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class SimpleMusicLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=128, num_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # LSTM принимает (pitch, duration, rest) напрямую\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=3,\n",
    "            hidden_size=hidden_size, # размер скрытого состояния\n",
    "            num_layers=num_layers,   # количество слоев LSTM\n",
    "            batch_first=True,        # формат [batch, seq, features]\n",
    "            dropout=0.2 if num_layers > 1 else 0  # dropout между слоями\n",
    "        )\n",
    "\n",
    "        # Полносвязный слой для предсказания\n",
    "        self.fc = nn.Linear(hidden_size, 3)  # 3 выхода\n",
    "\n",
    "        # Dropout для регуляризации\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # Сохраняем параметры\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_length, 3]\n",
    "               batch_size = количество последовательностей\n",
    "               seq_length = длина последовательности (например, 20)\n",
    "               3 = (pitch, duration, rest)\n",
    "\n",
    "        Returns:\n",
    "            prediction: [batch_size, 3] - следующая нота\n",
    "        \"\"\"\n",
    "        #    LSTM обрабатывает всю последовательность\n",
    "        #    Видит 20 нот, понимает паттерны\n",
    "        lstm_out, _ = self.lstm(x)  # [batch, seq_len, hidden_size]\n",
    "\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "\n",
    "        #  Применяем dropout (для регуляризации)\n",
    "        last_output = self.dropout(last_output)\n",
    "\n",
    "        #  Предсказываем следующую ноту\n",
    "        prediction = self.fc(last_output)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def init_hidden(self, batch_size, device='cpu'):\n",
    "        \"\"\"Инициализация скрытого состояния (для генерации)\"\"\"\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7bfd8f6de185a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:37:20.110287Z",
     "start_time": "2026-01-19T04:37:20.107785Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b0dc48219e073b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:37:20.148076Z",
     "start_time": "2026-01-19T04:37:20.132757Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_data_simple(songs, seq_length=20):\n",
    "    \"\"\"\n",
    "    Подготавливает данные для простой модели\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "\n",
    "    for song in songs:\n",
    "        if len(song) > seq_length:\n",
    "            # Разбиваем песню на последовательности\n",
    "            for i in range(len(song) - seq_length):\n",
    "                # Контекст: seq_length нот\n",
    "                sequence = song[i:i + seq_length]\n",
    "                #  следующая нота\n",
    "                target = song[i + seq_length]\n",
    "\n",
    "                X.append(sequence)\n",
    "                y.append(target)\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "\n",
    "    print(f\"Создано {len(X)} обучающих пар\")\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def train_simple_model(model, X_train, y_train, epochs=30, batch_size=64, lr=0.001):\n",
    "    \"\"\"Обучает модель\"\"\"\n",
    "\n",
    "    X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Оптимизатор и функция потерь\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # MSE loss для регрессии (предсказываем числа)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Обучение\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Прямой проход\n",
    "            predictions = model(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "\n",
    "            # Обратный проход\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Обучение завершено!\")\n",
    "    return model\n",
    "\n",
    "def generate_music_simple(model, seed_sequence, length=200, temperature=0.5):\n",
    "    \"\"\"\n",
    "    Генерирует музыку с помощью модели\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    current_sequence = seed_sequence.copy()\n",
    "    generated = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(length):\n",
    "            # Берем последние 20 нот (или меньше если начало)\n",
    "            if len(current_sequence) > 20:\n",
    "                context = current_sequence[-20:]\n",
    "            else:\n",
    "                context = current_sequence\n",
    "\n",
    "            # Добавляем padding если нужно\n",
    "            if len(context) < 20:\n",
    "                padding = [(0, 0, 0)] * (20 - len(context))\n",
    "                context = padding + context\n",
    "\n",
    "            # Конвертируем в тензор\n",
    "            context_tensor = torch.tensor([context], dtype=torch.float32)\n",
    "\n",
    "            # Предсказываем следующую ноту\n",
    "            prediction = model(context_tensor)[0]\n",
    "\n",
    "            # Добавляем немного случайности\n",
    "            noise = torch.randn_like(prediction) * temperature\n",
    "            predicted_note = prediction + noise\n",
    "\n",
    "            # Округляем и ограничиваем значения\n",
    "            pitch = int(torch.clamp(predicted_note[0], 0, 127).item())\n",
    "            duration = int(torch.clamp(predicted_note[1], 1, 16).item())\n",
    "            rest = int(torch.clamp(predicted_note[2], 0, 16).item())\n",
    "\n",
    "            next_note = (pitch, duration, rest)\n",
    "\n",
    "            current_sequence.append(next_note)\n",
    "            generated.append(next_note)\n",
    "\n",
    "    return generated\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a041e9a1105645",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c374ff124711ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:43:42.283524Z",
     "start_time": "2026-01-19T04:37:20.152465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создано 21897 обучающих пар\n",
      "X shape: (21897, 20, 3), y shape: (21897, 3)\n",
      "Epoch [5/30], Loss: 16.9391\n",
      "Epoch [10/30], Loss: 16.8706\n",
      "Epoch [15/30], Loss: 12.4234\n",
      "Epoch [20/30], Loss: 12.0933\n",
      "Epoch [25/30], Loss: 11.9998\n",
      "Epoch [30/30], Loss: 11.8934\n",
      "Обучение завершено!\n",
      "\n",
      "Генерация музыки...\n",
      "Сгенерировано 200 нот\n"
     ]
    }
   ],
   "source": [
    "# 1. Подготавливаем данные\n",
    "X, y = prepare_data_simple(songs, seq_length=20)\n",
    "\n",
    "# 2. Создаем модель\n",
    "model = SimpleMusicLSTM(hidden_size=128, num_layers=2)\n",
    "\n",
    "# 3. Обучаем\n",
    "model = train_simple_model(\n",
    "    model, X, y,\n",
    "    epochs=25,\n",
    "    batch_size=64,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# 4. Генерируем музыку\n",
    "print(\"\\nГенерация музыки...\")\n",
    "\n",
    "\n",
    "seed = songs[0][:10]  # первые 10 нот первой песни\n",
    "\n",
    "generated_music = generate_music_simple(\n",
    "    model, seed,\n",
    "    length=200,\n",
    "    temperature=0.3  # немного случайности\n",
    ")\n",
    "\n",
    "print(f\"Сгенерировано {len(generated_music)} нот\")\n",
    "\n",
    "\n",
    "# model, music\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f258230da242a06",
   "metadata": {},
   "source": [
    "2. (типа мини эмбединг добавили)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b120559844537c20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:57:52.980307Z",
     "start_time": "2026-01-19T04:57:52.955736Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImprovedSimpleLSTM(nn.Module):\n",
    "    \"\"\"Улучшенная версия вашей модели с минимумом изменений\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size=128, num_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Добавляем один полносвязный слой перед LSTM\n",
    "        self.input_projection = nn.Linear(3, 64)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=64,  # было 3, стало 64\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2 if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 3)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Проекция входных признаков (упрощенный аналог эмбеддингов)\n",
    "        x_proj = torch.relu(self.input_projection(x))\n",
    "        x_proj = self.dropout(x_proj)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x_proj)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        last_output = self.dropout(last_output)\n",
    "\n",
    "        prediction = self.fc(last_output)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d23fbfda652442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T05:00:20.859412Z",
     "start_time": "2026-01-19T04:58:12.056209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создано 7427 обучающих пар\n",
      "X shape: (7427, 20, 3), y shape: (7427, 3)\n",
      "Epoch [5/25], Loss: 79.0984\n",
      "Epoch [10/25], Loss: 15.0494\n",
      "Epoch [15/25], Loss: 15.0115\n",
      "Epoch [20/25], Loss: 15.0074\n",
      "Epoch [25/25], Loss: 14.7635\n",
      "Обучение завершено!\n",
      "\n",
      "Генерация музыки...\n",
      "Сгенерировано 200 нот\n"
     ]
    }
   ],
   "source": [
    "# 1. Подготавливаем данные\n",
    "X, y = prepare_data_simple(songs[:500], seq_length=20)\n",
    "\n",
    "# 2. Создаем модель\n",
    "model = ImprovedSimpleLSTM(hidden_size=128, num_layers=2)\n",
    "\n",
    "# 3. Обучаем\n",
    "model = train_simple_model(\n",
    "    model, X, y,\n",
    "    epochs=25,\n",
    "    batch_size=64,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# 4. Генерируем музыку\n",
    "print(\"\\nГенерация музыки...\")\n",
    "\n",
    "# Берем seed из данных\n",
    "seed = songs[0][:10]  # первые 10 нот первой песни\n",
    "\n",
    "generated_music = generate_music_simple(\n",
    "    model, seed,\n",
    "    length=200,\n",
    "    temperature=0.4  # немного случайности\n",
    ")\n",
    "\n",
    "print(f\"Сгенерировано {len(generated_music)} нот\")\n",
    "\n",
    "\n",
    "# model, music\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31478792f465e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2039d17e65a9dace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T05:15:23.256881Z",
     "start_time": "2026-01-19T05:15:23.236599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'markov2_2.mid'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokens_to_midi(tokens, out_midi=\"markov.mid\", resolution=480, step_division=8, program=102):\n",
    "    step_ticks = resolution // step_division\n",
    "    music = muspy.Music(resolution=resolution)\n",
    "    track = muspy.Track(program=program)\n",
    "    music.tracks.append(track)\n",
    "\n",
    "    t = 0\n",
    "    for pitch, dur, rest in tokens:\n",
    "        t += int(rest) * step_ticks\n",
    "        track.notes.append(muspy.Note(time=t, pitch=int(pitch), duration=int(dur) * step_ticks, velocity=80))\n",
    "        t += int(dur) * step_ticks\n",
    "\n",
    "    muspy.write_midi(out_midi, music)\n",
    "    return out_midi\n",
    "\n",
    "tokens_to_midi(generated_music, MODELS + \"/models2_2.mid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e657289a06e56",
   "metadata": {},
   "source": [
    "пока плохо, можно попробовать во время обучения - штрафовать модель за подряд несколько повторяющихся нот (хотя для немецкой музыки это как рах норм)\n",
    "\n",
    "Зато если наложить аккорды, то может и норм.\n",
    "\n",
    "или совместить так же генерить аккорды отдельно - и потом совместить с этим."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f90083928e503",
   "metadata": {},
   "source": "Как я поняла, соль в том, что в маркоской цепи переход зависит от последней ноту, а здесь от последних 20. (я такую модель потыкала), поэтому так."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Добавим аккорды",
   "id": "ed0421a34b5981ed"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a0073c13db2f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T05:23:07.726988Z",
     "start_time": "2026-01-19T05:23:07.684383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Готово! Сохранено: models_exp/models_akk2_v2.mid\n",
      "  Всего нот: 350\n",
      "  Фортепиано, один трек, всё слышно!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models_exp/models_akk2_v2.mid'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_chords_to_melody(melody_tokens, chord_interval=4):\n",
    "    \"\"\"\n",
    "    Добавляет аккорды к мелодии.\n",
    "    Возвращает список всех нот (мелодия + аккорды) для одного трека.\n",
    "    \"\"\"\n",
    "    all_notes = []\n",
    "\n",
    "    for i, (pitch, dur, rest) in enumerate(melody_tokens):\n",
    "        all_notes.append(('melody', pitch, dur, rest))\n",
    "\n",
    "        # Добавляем аккорд каждые chord_interval нот\n",
    "        if i % chord_interval == 0:\n",
    "            # Строим простой мажорный аккорд от ноты мелодии\n",
    "            base_pitch = int(pitch)\n",
    "\n",
    "            # (мажорное трезвучие)\n",
    "            chord_notes = [\n",
    "                base_pitch,  # основной тон\n",
    "                base_pitch + 4,  # большая терция\n",
    "                base_pitch + 7  # чистая квинта\n",
    "            ]\n",
    "\n",
    "            # Добавляем каждую ноту аккорда\n",
    "            for chord_note in chord_notes:\n",
    "                # Аккорд звучит дольше (в 2 раза дольше ноты мелодии)\n",
    "                all_notes.append(('chord', chord_note, dur * 3, 0))\n",
    "\n",
    "    return all_notes\n",
    "\n",
    "\n",
    "speed_k = 60 # 120 по дефолту\n",
    "\n",
    "def save_all_in_one_track(all_notes, filename=\"complete_music.mid\"):\n",
    "    \"\"\"\n",
    "    Сохраняет все ноты (мелодию и аккорды) в один трек.\n",
    "    Мелодия громче, аккорды тише - всё слышно\n",
    "    \"\"\"\n",
    "    music = muspy.Music(resolution=480)\n",
    "    track = muspy.Track(program=0)  # фортепиано\n",
    "    music.tracks.append(track)\n",
    "\n",
    "    t = 0\n",
    "    for note_type, pitch, dur, rest in all_notes:\n",
    "        # Учитываем паузу\n",
    "        t += int(rest) * speed_k\n",
    "\n",
    "        # Настраиваем громкость: мелодия громче, аккорды тише\n",
    "        velocity = 80 if note_type == 'melody' else 60\n",
    "\n",
    "        # Добавляем ноту\n",
    "        track.notes.append(muspy.Note(\n",
    "            time=t,\n",
    "            pitch=int(pitch),\n",
    "            duration=int(dur) * speed_k,\n",
    "            velocity=velocity\n",
    "        ))\n",
    "\n",
    "        # Для мелодии двигаем время вперед\n",
    "        # Для аккордов - нет, они звучат параллельно\n",
    "        if note_type == 'melody':\n",
    "            t += int(dur) * speed_k\n",
    "\n",
    "    muspy.write_midi(filename, music)\n",
    "    print(f\"✓ Готово! Сохранено: {filename}\")\n",
    "    print(f\"  Всего нот: {len(all_notes)}\")\n",
    "    print(f\"  Фортепиано, один трек, всё слышно!\")\n",
    "    return filename\n",
    "\n",
    "\n",
    "all_notes = add_chords_to_melody(generated_music)\n",
    "save_all_in_one_track(all_notes, filename=f'{MODELS}/models_akk2_v2.mid')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
